{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps for accleration.\n"
     ]
    }
   ],
   "source": [
    "# Start importing the necessary libraries\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from typing import Callable, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchmetrics as metrics\n",
    "import torchvision.io as tvio\n",
    "import torchvision.transforms.v2 as T\n",
    "import torchvision.transforms.v2.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Filter warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set device for acceleration\n",
    "DEVICE = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "if DEVICE == \"mps\":\n",
    "    torch.mps.empty_cache()\n",
    "elif DEVICE == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\n",
    "    \"Using CPU for training and testing as no accelerator is available.\"\n",
    "    if DEVICE == \"cpu\"\n",
    "    else f\"Using {DEVICE} for accleration.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters in this cell\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 100\n",
    "SHUFFLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start defininig datsets and dataloaders\n",
    "class CarImagesDataset(data.Dataset):\n",
    "    def __init__(self, path_to_dataset: str = None, data_aug_pipeline=None) -> None:\n",
    "        self.root_dir = path_to_dataset\n",
    "        self.files = os.listdir(path_to_dataset)\n",
    "        self.n_files = len(self.files)\n",
    "        self.data_aug_pipeline = data_aug_pipeline\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.n_files\n",
    "\n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        total_path = f\"{self.root_dir}/{self.files[idx]}\"\n",
    "        image_tensor = tvio.read_image(total_path)\n",
    "\n",
    "        if self.data_aug_pipeline is not None:\n",
    "            image_tensor = self.data_aug_pipeline(image_tensor)\n",
    "\n",
    "        return image_tensor\n",
    "\n",
    "\n",
    "class SatelliteImageDataset(data.Dataset):\n",
    "    def __init__(self, path_to_dataset: str = None, data_aug_pipeline=None) -> None:\n",
    "        self.root_dir = path_to_dataset\n",
    "        self.files = os.listdir(path_to_dataset)\n",
    "        self.n_files = len(self.files)\n",
    "        self.data_aug_pipeline = data_aug_pipeline\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.n_files\n",
    "\n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        total_path = f\"{self.root_dir}/{self.files[idx]}\"\n",
    "        image_tensor = tvio.read_image(total_path)\n",
    "\n",
    "        if self.data_aug_pipeline is not None:\n",
    "            image_tensor = self.data_aug_pipeline(image_tensor)\n",
    "\n",
    "        return image_tensor\n",
    "\n",
    "\n",
    "car_images_train_transform = T.Compose(\n",
    "    [\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomVerticalFlip(p=0.5),\n",
    "        T.RandomRotation(degrees=45),\n",
    "        T.RandomResizedCrop(size=(256, 256), scale=(0.8, 1.0)),\n",
    "        T.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        T.RandomPerspective(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "satellite_images_train_transform = T.Compose(\n",
    "    [\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomVerticalFlip(p=0.5),\n",
    "        T.RandomRotation(degrees=45),\n",
    "        T.RandomResizedCrop(size=(256, 256), scale=(0.8, 1.0)),\n",
    "        T.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        T.RandomPerspective(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the Datasets and DataLoaders\n",
    "\n",
    "## Training Datasets\n",
    "\n",
    "# TODO: Add dataset paths\n",
    "car_images_train_unaugmented = CarImagesDataset()\n",
    "car_images_train_augmented = CarImagesDataset(\n",
    "    data_aug_pipeline=car_images_train_transform\n",
    ")\n",
    "car_images_train = data.ConcatDataset(\n",
    "    [car_images_train_unaugmented, car_images_train_augmented]\n",
    ")\n",
    "\n",
    "satellite_images_train_unaugmented = SatelliteImageDataset()\n",
    "satellite_images_train_augmented = SatelliteImageDataset(\n",
    "    data_aug_pipeline=satellite_images_train_transform\n",
    ")\n",
    "satellite_images_train = data.ConcatDataset(\n",
    "    [satellite_images_train_unaugmented, satellite_images_train_augmented]\n",
    ")\n",
    "\n",
    "## Testing Datasets\n",
    "car_images_test = CarImagesDataset()\n",
    "satellite_images_test = SatelliteImageDataset()\n",
    "\n",
    "## Dataloaders\n",
    "car_images_train_loader = data.DataLoader(\n",
    "    car_images_train, batch_size=BATCH_SIZE, shuffle=SHUFFLE\n",
    ")\n",
    "satellite_images_train_loader = data.DataLoader(\n",
    "    satellite_images_train, batch_size=BATCH_SIZE, shuffle=SHUFFLE\n",
    ")\n",
    "\n",
    "car_images_test_loader = data.DataLoader(\n",
    "    car_images_test, batch_size=BATCH_SIZE, shuffle=SHUFFLE\n",
    ")\n",
    "satellite_images_test_loader = data.DataLoader(\n",
    "    satellite_images_test, batch_size=BATCH_SIZE, shuffle=SHUFFLE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_img = random.choice(car_images_train)\n",
    "\n",
    "# plt.imshow(random_img.permute(1, 2, 0).numpy())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 64, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 28, 28])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Model Architecture here\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                padding_mode=\"reflect\",\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(out_channels),\n",
    "            nn.Conv2d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                padding_mode=\"reflect\",\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int = 2) -> None:\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.encoder = nn.ModuleList(\n",
    "            [\n",
    "                ConvBlock(in_channels, 64),\n",
    "                ConvBlock(64, 128),\n",
    "                ConvBlock(128, 256),\n",
    "                ConvBlock(256, 512),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.base = nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv2d(512, 1024, kernel_size=3, padding_mode=\"reflect\"),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(1024, 1024, kernel_size=3, padding_mode=\"reflect\"),\n",
    "                nn.ReLU(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.ModuleList()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # TODO: Add the skip connections and add them to the decoder\n",
    "        copied_feature_maps = []\n",
    "\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "            copied_feature_maps.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        print(copied_feature_maps[-1].shape)\n",
    "\n",
    "        for layer in self.base:\n",
    "            x = layer(x)\n",
    "\n",
    "        for layer in self.decoder:\n",
    "            x = layer(x)\n",
    "            # TODO: IMPLEMENT CROPPING AND CONCATENATION\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# test the block and model\n",
    "test_image = torch.randint(0, 256, (1, 572, 572), dtype=torch.float32)\n",
    "test_batch = torch.randint(0, 256, (3, 1, 572, 572), dtype=torch.float32)\n",
    "\n",
    "block = UNet(1, 2)\n",
    "\n",
    "conv_out = block(test_image)\n",
    "conv_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Integrate metrics into train function\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    train_loader: data.DataLoader,\n",
    "    val_loader: data.DataLoader = None,\n",
    "    epochs: int = 15,\n",
    "    device: str = \"cpu\",\n",
    "    metrics_to_monitor: str | List[Callable] | None = None,\n",
    "):\n",
    "    _epoch_wise_train_loss = []\n",
    "    _epoch_wise_val_loss = []\n",
    "\n",
    "    _epoch_wise_train_accuracy = []\n",
    "    _epoch_wise_val_accuracy = []\n",
    "\n",
    "    if metrics_to_monitor is None:\n",
    "        metrics_to_monitor = []\n",
    "\n",
    "    try:\n",
    "        _n_batches = len(train_loader)\n",
    "        _max_char_epoch, _max_char_batch = len(str(epochs)), len(str(_n_batches))\n",
    "\n",
    "        # BATCH TRAIN FORMAT STRING\n",
    "        def _batch_train_message(i_epoch, i_batch):\n",
    "            return f\"Epoch {i_epoch:>{_max_char_epoch}}/{epochs} Batch: [{i_batch:>{_max_char_batch}}/{_n_batches}]\"\n",
    "\n",
    "        # CREATE EPOCH TRAIN FORMAT STRING\n",
    "        def _epoch_train_message(\n",
    "            i_epoch, i_batch, t_loss, t_accuracy, v_loss=None, v_accuracy=None\n",
    "        ):\n",
    "            return (\n",
    "                f\"Epoch {i_epoch:>{_max_char_epoch}}/{epochs} Batch: [{i_batch:>{_max_char_batch}}/{_n_batches}] Train Loss: {t_loss:.4f} Train Accuracy: {t_accuracy:.4f}\"\n",
    "                if v_loss is None or v_accuracy is None\n",
    "                else f\"Epoch {i_epoch:>{_max_char_epoch}}/{epochs} Batch: [{i_batch:>{_max_char_batch}}/{_n_batches}] Train Loss: {t_loss:.4f} Train Accuracy: {t_accuracy:.4f} Val Loss: {v_loss:.4f} Val Accuracy: {v_accuracy:.4f}\"\n",
    "            )\n",
    "\n",
    "        # Move model to device\n",
    "        model.to(device)\n",
    "        print(f\"Model moved to {device}.\")\n",
    "\n",
    "        # Train the model\n",
    "        print(\"++++++++++ MODEL TRAINING STARTS ++++++++++\")\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            _batch_wise_train_loss = []\n",
    "            _batch_wise_accuracy = []\n",
    "\n",
    "            # Run batches\n",
    "            for batch_idx, (data_img, labels) in enumerate(train_loader, 1):\n",
    "                model.train()\n",
    "                print(_batch_train_message(epoch, batch_idx), end=\"\\r\")\n",
    "\n",
    "                # Move data to device\n",
    "                data_img, labels = data_img.to(device), labels.to(device)\n",
    "\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(data_img)\n",
    "\n",
    "                # Get accuracy\n",
    "                batch_accuracy = torch.sum(\n",
    "                    torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)\n",
    "                ).item() / len(labels)\n",
    "                _batch_wise_accuracy.append(batch_accuracy)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                _batch_wise_train_loss.append(loss.item())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                del data_img, labels, outputs, loss\n",
    "\n",
    "            _t_loss = torch.mean(torch.tensor(_batch_wise_train_loss))\n",
    "            _t_accuracy = torch.mean(torch.tensor(_batch_wise_accuracy))\n",
    "\n",
    "            _epoch_wise_train_loss.append(_t_loss.item())\n",
    "            _epoch_wise_train_accuracy.append(_t_accuracy)\n",
    "\n",
    "            # Validation\n",
    "            if val_loader:\n",
    "                model.eval()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    _batch_wise_val_loss = []\n",
    "                    _batch_wise_accuracy = []\n",
    "\n",
    "                    for data_img, labels in val_loader:\n",
    "                        data_img, labels = data_img.to(device), labels.to(device)\n",
    "                        outputs = model(data_img)\n",
    "\n",
    "                        accuracy = torch.sum(\n",
    "                            torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)\n",
    "                        ).item() / len(labels)\n",
    "                        _batch_wise_accuracy.append(accuracy)\n",
    "\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        _batch_wise_val_loss.append(loss.item())\n",
    "                        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "                        del data_img, labels, outputs, loss, predictions\n",
    "\n",
    "                    _v_loss = torch.mean(torch.tensor(_batch_wise_val_loss))\n",
    "                    _epoch_wise_val_loss.append(_v_loss.item())\n",
    "\n",
    "                    _v_accuracy = torch.mean(torch.tensor(_batch_wise_accuracy))\n",
    "                    _epoch_wise_val_accuracy.append(_v_accuracy.item())\n",
    "\n",
    "            print(\n",
    "                _epoch_train_message(\n",
    "                    epoch, batch_idx, _t_loss, _t_accuracy, _v_loss, _v_accuracy\n",
    "                )\n",
    "            )\n",
    "\n",
    "    except RuntimeError as re:\n",
    "        print(\"++++++++++ MODEL TRAINING ENDS ++++++++++\")\n",
    "        print(\"Some error occurred. Training stopped.\")\n",
    "        print(re)\n",
    "        return\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\")\n",
    "        print(\"++++++++++ MODEL TRAINING ENDS ++++++++++\")\n",
    "        print(\"Training interrupted.\")\n",
    "\n",
    "    print(\"++++++++++ MODEL TRAINING ENDS ++++++++++\")\n",
    "    print(\"Training completed.\")\n",
    "    return {\n",
    "        \"train_loss\": _epoch_wise_train_loss,\n",
    "        \"val_loss\": _epoch_wise_val_loss,\n",
    "        \"train_accuracy\": _epoch_wise_train_accuracy,\n",
    "        \"val_accuracy\": _epoch_wise_val_accuracy,\n",
    "    }\n",
    "\n",
    "\n",
    "def test(model, test_loader, criterion, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "\n",
    "    _n_test_batches = len(test_loader)\n",
    "    _max_char_batch = len(str(_n_test_batches))\n",
    "\n",
    "    _test_accuracy, _test_loss = [], []\n",
    "\n",
    "    for batch_idx, (data_img, labels) in enumerate(test_loader, 1):\n",
    "        # Set model to eval mode\n",
    "        model.eval()\n",
    "\n",
    "        # Log the batch testing\n",
    "        print(f\"Batch: [{batch_idx:>{_max_char_batch}}/{_n_test_batches}]\", end=\"\\r\")\n",
    "\n",
    "        # Move data and label to device\n",
    "        data_img, labels = data_img.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data_img)\n",
    "\n",
    "        # Get accuracy\n",
    "        _accuracy = torch.sum(\n",
    "            torch.argmax(outputs) == torch.argmax(labels)\n",
    "        ).item() / len(labels)\n",
    "\n",
    "        _test_loss.append(criterion(outputs, labels).item())\n",
    "        _test_accuracy.append(_accuracy)\n",
    "\n",
    "    # Finally move model back to CPU so that other models can use the GPU\n",
    "    model.to(\"cpu\")\n",
    "\n",
    "    return {\n",
    "        \"test_loss\": torch.mean(torch.tensor(_test_loss)).item(),\n",
    "        \"test_accuracy\": torch.mean(torch.tensor(_test_accuracy)).item(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet(1, 1)  # TODO: Add proper parameters\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.99)\n",
    "# loss = nn.CrossEntropyLoss() # TODO: Add correct loss function\n",
    "\n",
    "# train(\n",
    "#     model,\n",
    "#     optimizer,\n",
    "#     loss,\n",
    "#     car_images_train_loader,\n",
    "#     car_images_test_loader,\n",
    "#     epochs=EPOCHS,\n",
    "#     device=DEVICE,\n",
    "#     metrics_to_monitor=[metrics.Dice(num_classes=2, average=\"micro\")],\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "northeastern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
